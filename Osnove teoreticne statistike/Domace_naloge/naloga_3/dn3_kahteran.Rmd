---
title: "Domača naloga 3"
subtitle: "Osnove teoretične statistike"
author: "Alen Kahteran"
date: "06. 01. 2020"
output:
  html_document:
    fig_caption: no
    toc: no
    toc_depth: '3'
params:
  printcode: no
  printresults: hide
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=params$printcode, results=params$printresults, warning=FALSE, message=FALSE)
```

### 1. 

$$
\sum_{i=1}^n\left(X_i - \overline{X}\right)^2 = \sum_{i=1}^n\left(X_i^2 - 2X_i\overline{X} + \overline{X}^2\right) \,.
$$

Razširimo kvadrat

$$
\sum_{i=1}^n\left(X_i^2 - 2X_i\overline{X} + \overline{X}^2\right) = \sum_{i=1}^nX_i^2 - \sum_{i=1}^n2X_i\overline{X} + \sum_{i=1}^n\overline{X}^2 \,.
$$

Razdelimo na posamezne vsote

$$
\sum_{i=1}^nX_i^2 - \sum_{i=1}^n2X_i\overline{X} + \sum_{i=1}^n\overline{X}^2 = \sum_{i=1}^nX_i^2 - 2\overline{X}\sum_{i=1}^nX_i + \overline{X}^2\sum_{i=1}^n1 \,.
$$

Nekoliko preoblikujemo in dobimo

$$
\sum_{i=1}^nX_i^2 - 2\overline{X}\sum_{i=1}^nX_i + \overline{X}^2\sum_{i=1}^n1 = n\frac{1}{n}\sum_{i=1}^nX_i^2 - n\frac{1}{n}2\overline{X}\sum_{i=1}^nX_i + n\overline{X}^2 \,.
$$

Za zadnjo vsoto vemo da je enaka $n$, medtem ko za prvi dve naredimo naslednje

$$
n\frac{1}{n}\sum_{i=1}^nX_i^2 - n\frac{1}{n}2\overline{X}\sum_{i=1}^nX_i + n\overline{X}^2 = n\overline{X^2} - 2n\overline{X}^2 + n\overline{X}^2 \,.
$$

Sedaj lahko poračunamo tudi preostali dve vsoti.

$$
n\overline{X^2} - 2n\overline{X}^2 + n\overline{X}^2 = n\overline{X^2} - n\overline{X}^2\,.
$$
To lahko zapišemo tudi kot 

$$
n\overline{X^2} - n\overline{X}^2 = n\left(\overline{X^2} - \overline{X}^2\right)\,.
$$

za kar pa vemo da velja

$$
n\left(\overline{X^2} - \overline{X}^2\right) = n\left(\mu_2-\mu_1^2\right)\,.
$$

### 2.

Varianco izračunamo na naslednji način

$$
Var\left(X\right)=E[X^2]-E[X]^2 \,.
$$
Poleg tega vemo da velja naslednje

$$
\mu_k = E[X^k] \,.
$$
Se pravi lahko varianco zapišemo tudi kot

$$
Var\left(X\right) = \mu_2 - \mu_1^2 \,.
$$

Se pravi cenilko $\hat{\sigma^2}$ lahko zapišemo kot

$$
\hat{\sigma^2} = \hat{\mu_2} - \hat{\mu_1}^2 \,,
$$
za $\hat{\mu_k}$ pa vemo da velja

$$
\hat{\mu_k} = \frac{1}{n}\sum_{i=1}^nX_i^k \,.
$$
### 3.

Da pokažemo da je cenilka nepristranska mora veljati

$$
E\left[\hat{\sigma^2}\right] = \sigma^2 \,.
$$
Torej $E[\hat{\sigma^2}]$ lahko zapišemo kot

$$
E\left[\hat{\sigma^2}\right] = E\left[\hat{\mu_2} - \hat{\mu_1}^2\right]
$$

Podobno smo dobili že pri prvi točki in če to pravilno pripeljemo v enačbo dobimo

$$
E\left[\hat{\mu_2} - \hat{\mu_1}^2\right] = E\left[\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X})^2\right] \,.
$$


V oklepaju vse skupaj pomnožimo z $\frac{n-1}{n-1}$

$$
E\left[\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X})^2\right] = E\left[\frac{n-1}{n-1}\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X})^2\right] \,,
$$
kar je enako
$$
E\left[\frac{n-1}{n-1}\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X})^2\right] = E\left[\frac{n-1}{n}\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2\right] \,.
$$

Iz pričakovane vrednosti lahko "potegnemo" konstanto $\frac{n-1}{n}$

$$
E\left[\frac{n-1}{n}\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2\right] = \frac{n-1}{n}E\left[\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2\right] \,.
$$
Za slednje vemo da velja
$$
E\left[\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2\right] = \sigma^2 \,.
$$
Torej dobili smo naslednje

$$
\frac{n-1}{n}E\left[\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2\right] = \frac{n-1}{n}\sigma^2 \,.
$$
Se pravi za $E\left[\hat{\sigma^2}\right]$ lahko trdimo

$$
E\left[\hat{\sigma^2}\right] = \frac{n-1}{n}\sigma^2 \,.
$$

kar pa ni enako $\sigma^2$, in posledično vidimo da je cenilka pristranska.

### 4.

a.) Izbral sem si tri različne porazdelitve, z namenom da bo videti kako je cenilka pristranska ne glede na porazdelitev. Izbral sem si Poissonovo porazdelitev (diskretna), $\chi^2$ porazdelitev z $3$ stopinjami prostosti (zvezna asimetrična) ter normalno porazdelitev (zvezna simetrična).

b.) Ker analitično vemo kakšne so variance teh porazdelitev, jih lahko določimo da bodo vse enake (v našem primeru sem si izbral $4$).

Variance in parametri so sledeči
$$
Var_{pois}(X) = \lambda = 4 \,,
$$

$$
Var_{\chi^2}(X) = 2k = 4 \,,
$$


$$
Var_{norm}(X) = \sigma^2 = 4 \,,
$$
kjer $k$ predstavlja število stopinj prostosti in je v našem primeru $2$. $\sigma$ je ravno tako enaka $2$, da bodo vse variance enake.


c.) Za preverjanje pristranosti je pomembno da je vzorec porazdelitve majhen, saj je tu bolje videti pristranost. Če je vzorec prevelik se že preveč "spuščamo" v doslednost cenilke. Vzorec za simulacije bo torej velikosti $10^4$.


```{r, echo=TRUE, eval=TRUE, results="markup"}

sim_n <- 10^4
n <- 10
k <- 2
sig <- 2
lambda <- 4


var_estimator <- function(smpl, n){
    estimate <- 1/n*sum(smpl^2) - (1/n*sum(smpl))^2
    return(estimate)
}

# reproducibilnost
set.seed(8)

# diskretna
pois_var <- replicate(sim_n, var_estimator(rpois(n, lambda=lambda), n))

# zvezna nesimetricna
chsq_var <- replicate(sim_n, var_estimator(rchisq(n, df=k), n))

# zvezna simetricna
norm_var <- replicate(sim_n, var_estimator(rnorm(n, sd=sig), n))

mean(pois_var)
mean(chsq_var)
mean(norm_var)

```

Če stvar ponovimo z veliko večjim vzorcem bomo pa videli da je cenilka dosledna.

```{r, echo=TRUE, eval=TRUE, results="markup"}

# spremenimo vzorec za varianco
n <- 1000

# diskretna
pois_var <- replicate(sim_n, var_estimator(rpois(n, lambda=lambda), n))

# zvezna nesimetricna
chsq_var <- replicate(sim_n, var_estimator(rchisq(n, df=k), n))

# zvezna simetricna
norm_var <- replicate(sim_n, var_estimator(rnorm(n, sd=sig), n))

mean(pois_var)
mean(chsq_var)
mean(norm_var)

```
