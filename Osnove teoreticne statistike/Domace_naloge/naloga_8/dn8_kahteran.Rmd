---
title: "Domača naloga 8"
subtitle: "Osnove teoretične statistike"
author: "Alen Kahteran"
date: "31. 03. 2021"
output:
  html_document:
    fig_caption: no
    toc: no
    toc_depth: '3'
params:
  printcode: no
  printresults: hide
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=params$printcode, results=params$printresults, warning=FALSE, message=FALSE)
library(knitr)
library(kableExtra)
library(tidyverse)
```

# 1.

Ničeloga domneva ki jo bomo preverjali je 

$$
H_0: \lambda_1 = \lambda_2 = \lambda_3 \,.
$$

Alternativna domneva je

$$
H_A:\lambda_i \neq \lambda_j \,,
$$
kjer $i$ in $j$ nista enaki števili. (vsaj en par se razlikuje)

# 2.

Vemo da velja

$$
L(x, \lambda) = \prod_{i=1}^3\prod_{j=1}^{n_i} \lambda_0\exp(-\lambda_0x_{ij})\,.
$$

Če to logaritmiramo dobimo

$$
l(x, \lambda) = \sum_{i=1}^3\sum_{j=1}^{n_i}\left(\log(\lambda_0) - \lambda_0x_{ij}\right) \,.
$$

Parcialogo odvajamo po $\lambda_0$

$$
\frac{\partial l(x, \lambda)}{\partial\lambda_0} = \frac{\sum_{i=1}^3n_i}{\lambda_0} - \sum_{i=1}^3\sum_{j=1}^{n_i}x_{ij} \,.
$$

Iščemo ekstrem, nekoliko premečemo in dobimo

$$
\hat{\lambda_0} = \frac{\sum_{i=1}^3n_i}{\sum_{i=1}^3\sum_{j=1}^{n_i}x_{ij}} \,.
$$

Podobno naredimo MLE za $\lambda_i$ in dobimo

$$
\hat{\lambda_i} = \frac{n_i}{\sum_{j=1}^{n_i}x_j} \,.
$$

Naredimo še LRT

$$
\Lambda = \frac{\prod_{i=1}^3\prod_{j=1}^{n_i} \hat\lambda_i\exp(-\hat\lambda_ix_{ij})}{\prod_{i=1}^3\prod_{j=1}^{n_i} \hat\lambda_0\exp(-\hat\lambda_0x_{ij})} \,.
$$
Ko "vnesemo" prej izračunane stvari se vse skupaj precej pokrajša in če vse skupaj še logaritmiramo in pomnožimo z $-2$ dobimo slednje, 

$$
-2\log(\Lambda) = -2\left(\sum_{i=1}^3\sum_{j=1}^{n_i}\log(\lambda_i) -\sum_{i=1}^{3}n_i\log(\lambda_0)\right) \,,
$$
kar lahko preoblikujemo v

$$
-2\log(\Lambda)=-2\left(\sum_{i=1}^{3}n_i\left(\log(\lambda_i) - \log(\lambda_0)\right)\right) \,,
$$

za kar vemo da velja

$$
-2\log(\Lambda) \sim\chi^2_{df=2} \,.
$$

# 3.

Da bi lahko dokazali pravo velikost testa moramo simulirati velike vzorce. In ker enačba višje velja le asimptotsko bi morali gledati za vsaj $100$ (težko argumentiram kaj je dovolj veliko, se mi pa zdi da bi to moralo pri takšnih velikostih vzorca že veljati).

Glede izbire $\lambda$ se mi zdi da je pravzaprav vseeno, saj je za vse tri vzorce enak, ga pa na podlagi naključnih števil ocenimo, saj to velja tudi za testno statistiko. Odločil sem se za vrednost $1$.

<!-- Nisem prepričan edino v katerem primeru bi težje razlikovali med primeri namreč pri višjih vrednosti $\lambda$ bi bila eksponentna porazdelitev bolj "strma" vendar ker je v enačbi $1/\exp(\lambda)$, velja ravno obratno in je bolj položno vse skupaj, kar bi predstavljalo daljšo življensko dobo. Kar je tudi nekoliko intuitivno. -->

```{r, echo=TRUE, eval=TRUE, results="markup"}

set.seed(8)

test_stat <- function(lambda, n_1, n_2, n_3) {
    
    rand_n1 <- rexp(n_1, lambda)
    rand_n2 <- rexp(n_2, lambda)
    rand_n3 <- rexp(n_3, lambda)
    
    lmbd_0 <- sum(n_1, n_2, n_3) / sum(rand_n1, rand_n2, rand_n3)
    # lmbd_0 <- lambda
    lmbd_1 <- n_1/sum(rand_n1)
    lmbd_2 <- n_2/sum(rand_n2)
    lmbd_3 <- n_3/sum(rand_n3)
    

    result <- ((sum(n_1, n_2, n_3)*log(lmbd_0) - 
                    lmbd_0*(sum(rand_n1, rand_n2, rand_n3))) - 
                   (n_1*log(lmbd_1) - lmbd_1*sum(rand_n1)) - 
                   (n_2*log(lmbd_2) - lmbd_2*sum(rand_n2)) - 
                   (n_3*log(lmbd_3) - lmbd_3*sum(rand_n3)))
    
    return(-2*result)
    }


n_reps <- 987654

p_values <- pchisq(
    replicate(n_reps, 
              test_stat(1, 99, 100, 101)
              ), 
    df=2, 
    lower.tail = FALSE
    )

reject_rate <- length(p_values[p_values < 0.05])/n_reps

```

Opravimo $987654$ ponovitev simulacij, kjer dobimo delež zavrnitve $`r reject_rate`$ kar je pričakovano. Poglejmo si še porazdelitev, da nismo mogoče česa zgrešili.

```{r, echo=TRUE, eval=TRUE, results="markup"}

ggplot(data.frame(x=p_values), aes(x=x, y=..density..)) +
    geom_histogram(bins=50, col="black") +
    xlim(c(0,1)) +
    labs(x="p vrednost",
         y="Gostota")

```

# 4.

```{r, echo=TRUE, eval=TRUE, results="markup"}

n <- 100
alfa <- 0.05
n_sim <- (n*alfa*(1-alfa))/(0.00025/qnorm((1-alfa)/2))^2

```

Število simulacij, da bo širina $95\%$ intervala zaupanja največ $0.0005$ je $298843$. Torej smo že sedaj imeli dovolj veliko št. simulacij

# 5.

```{r, echo=TRUE, eval=TRUE, results="markup"}

p_values2 <- pchisq(
    replicate(n_reps, 
              test_stat(0.01, 2, 3, 4)
              ), 
    df=2, 
    lower.tail = FALSE
    )

ggplot(data.frame(x=p_values2), aes(x=x, y=..density..)) +
    geom_histogram(bins=50, col="black") +
    xlim(c(0,1)) +
    labs(x="p vrednost",
         y="Gostota")

reject_rate <- length(p_values2[p_values2 < 0.05])/n_reps

```

Delež zavrnitve, za primer ko je $\lambda=0.01$, je $`r reject_rate`$.

```{r, echo=TRUE, eval=TRUE, results="markup"}
p_values3 <- pchisq(
    replicate(n_reps, 
              test_stat(10, 2, 3, 4)
              ), 
    df=2, 
    lower.tail = FALSE
    )

ggplot(data.frame(x=p_values3), aes(x=x, y=..density..)) +
    geom_histogram(bins=50, col="black") +
    xlim(c(0,1)) +
    labs(x="p vrednost",
         y="Gostota")


reject_rate <- length(p_values3[p_values3 < 0.05])/n_reps

```

Delež zavrnitve, za primer ko je $\lambda=10$, je $`r reject_rate`$. Velikost testa je v obeh primerih nekaj malega čez $0.062$. Torej bi lahko rekel da je velikost obeh testov enaka. Hkrati pa tudi vidimo da je test v obeh primerih liberalen ker večkrat zavrnemo ničelno domnevo.


